@inproceedings{lepriol2018adaptive,
  title={Adaptive Stochastic Dual Coordinate Ascent for Conditional Random Fields},
  author={Le Priol, R{\'e}mi and Pich{\'e}, Alexandre and Lacoste-Julien, Simon},
  booktitle={UAI},
  year={2018}
}


@inproceedings{Zhao2015StochasticOptimizationImportance,
  title = {Stochastic Optimization with Importance Sampling for Regularized Loss Minimization},
  booktitle = {ICML},
  author = {Zhao, Peilin and Zhang, Tong},
  year = {2015},
  file = {/Users/lepriolr/Drive/zotero_data/storage/VX3T7AFQ/Zhao and Zhang - 2015 - Stochastic Optimization with Importance Sampling f.pdf}
}


@incollection{Stich2017SafeAdaptiveImportance,
  title = {Safe Adaptive Importance Sampling},
  booktitle = {NIPS},
  author = {Stich, Sebastian U and Raj, Anant and Jaggi, Martin},
  year = {2017},
  file = {/Users/lepriolr/Drive/zotero_data/storage/GRPXRZ9G/Stich et al. - 2017 - Safe Adaptive Importance Sampling.pdf;/Users/lepriolr/Drive/zotero_data/storage/UZFS6GKU/7025-safe-adaptive-importance-sampling.html}
}


@book{kakade_duality_2009,
	title = {On the duality of strong convexity and strong smoothness: {Learning} applications and matrix regularization},
	shorttitle = {On the duality of strong convexity and strong smoothness},
	abstract = {We show that a function is strongly convex with respect to some norm if and only if its conjugate function is strongly smooth with respect to the dual norm. This result has already been found to be a key component in deriving and analyzing several learning algorithms. Utilizing this duality, we isolate a single inequality which seamlessly implies both generalization bounds and online regret bounds; and we show how to construct strongly convex functions over matrices based on strongly convex functions over vectors. The newly constructed functions (over matrices) inherit the strong convexity properties of the underlying vector functions. We demonstrate the potential of this framework by analyzing several learning algorithms including group Lasso, kernel learning, and online control with adversarial quadratic costs. 1},
	author = {Kakade, Sham M. and Shalev-shwartz, Shai and Tewari, Ambuj},
	year = {2009},
}


@article{shalev-shwartz_stochastic_2013,
	title = {Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization},
	volume = {14},
	journal = {Journal of Machine Learning Research},
	author = {Shalev-Shwartz, Shai and Zhang, Tong},
	year = {2013},
}

@inproceedings{shalev-shwartz_accelerated_2014,
	title = {Accelerated {Proximal} {Stochastic} {Dual} {Coordinate} {Ascent} for {Regularized} {Loss} {Minimization}},
	url = {http://proceedings.mlr.press/v32/shalev-shwartz14.html},
	language = {en},
	booktitle = {ICML},
	author = {Shalev-Shwartz, Shai and Zhang, Tong},
	year = {2014},
}

@article{shalev-shwartz_accelerated_2013-1,
	title = {Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization},
	journal = {arXiv:1309.2375},
	author = {Shalev-Shwartz, Shai and Zhang, Tong},
	year = {2013},
}

@inproceedings{csiba2015stochastic,
  title={Stochastic dual coordinate ascent with adaptive probabilities},
  author={Csiba, Dominik and Qu, Zheng and Richt{\'a}rik, Peter},
  booktitle={ICML},
  year={2015}
}

@inproceedings{shalev-shwartz_sdca_no_duality_2016,
	title = {{SDCA} without {Duality}, {Regularization}, and {Individual} {Convexity}},
	url = {http://proceedings.mlr.press/v48/shalev-shwartza16.html},
	language = {en},
	booktitle = {ICML},
	author = {Shalev-Shwartz, Shai},
	year = {2016},
}

@article{nesterov_efficiency_2012,
	title = {Efficiency of coordinate descent methods on huge-scale optimization problems},
	volume = {22},
	url = {http://epubs.siam.org/doi/abs/10.1137/100802001},
	journal = {SIAM Journal on Optimization},
	author = {Nesterov, Yurii},
	year = {2012},
}

@phdthesis{shalev-shwartz_online_2007,
	title = {Online {Learning}: {Theory}, {Algorithms}, and {Applications}},
	url = {http://w3.cs.huji.ac.il/~shais/papers/ShalevThesis07.pdf},
	author = {Shalev-Shwartz, Shai},
	year = {2007},
}

@article{muller_pystruct_2014,
	title = {pystruct - {Learning} {Structured} {Prediction} in {Python}},
	volume = {15},
	url = {http://www.jmlr.org/papers/v15/mueller14a.html},
	journal = {Journal of Machine Learning Research},
	author = {MÃ¼ller, Andreas C. and Behnke, Sven},
	year = {2014},
}

@inproceedings{osokin2016minding,
  title={Minding the gaps for block {Frank-Wolfe} optimization of structured {SVM}s},
  author={Osokin, Anton and Alayrac, Jean-Baptiste and Lukasewitz, Isabella and Dokania, Puneet and Lacoste-Julien, Simon},
  booktitle={ICML},
  year={2016}
}

@book{press_numerical_1992,
	address = {Cambridge},
	edition = {2nd},
	title = {Numerical recipes in {C}: the art of scientific computing},
	shorttitle = {Numerical recipes in {C}},
	publisher = {Cambridge University Press},
	author = {Press, William H. and Teukolsky, Saul A. and Vetterling, William T. and Flannery, Brian P.},
	year = {1992},
}

@article{collins2008exponentiated,
  title={Exponentiated gradient algorithms for conditional random fields and max-margin {M}arkov networks},
  author={Collins, Michael and Globerson, Amir and Koo, Terry and Carreras, Xavier and Bartlett, Peter L},
  journal={Journal of Machine Learning Research},
  year={2008}
}

@inproceedings{schmidt2015non,
  title={Non-uniform stochastic average gradient method for training conditional random fields},
  author={Schmidt, Mark and Babanezhad, Reza and Ahmed, Mohamed and Defazio, Aaron and Clifton, Ann and Sarkar, Anoop},
  booktitle={AISTATS},
  year={2015}
}

@article{taskar_structured_2006,
	title = {Structured {Prediction}, {Dual} {Extragradient} and {Bregman} {Projections}},
	volume = {7},
	url = {http://www.jmlr.org/papers/v7/taskar06a.html},
	journal = {Journal of Machine Learning Research},
	author = {Taskar, Ben and Lacoste-Julien, Simon and Jordan, Michael I.},
	year = {2006},
}

@inproceedings{defazio2014saga,
  title={{SAGA}: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{jaggi_revisiting_2013,
	title = {Revisiting {Frank}-{Wolfe}: {Projection}-{Free} {Sparse} {Convex} {Optimization}},
	shorttitle = {Revisiting {Frank}-{Wolfe}},
	url = {http://proceedings.mlr.press/v28/jaggi13.html},
	booktitle = {ICML},
	author = {Jaggi, Martin},
	year = {2013},
}

@inproceedings{taskar2004max,
  title={Max-margin {M}arkov networks},
  author={Taskar, Ben and Guestrin, Carlos and Koller, Daphne},
  booktitle={NIPS},
  year={2004}
}

@inproceedings{lafferty2001conditional,
  title={Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
  author={Lafferty, John and McCallum, Andrew and Pereira, Fernando CN},
  booktitle={ICML},
  year={2001}
}

@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  year={2017},
  publisher={Springer}
}

@inproceedings{roux2012stochastic,
  title={A stochastic gradient method with an exponential convergence rate for finite training sets},
  author={Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
  booktitle={NIPS},
  year={2012}
}

@MastersThesis{wallach2002efficient,
  title={Efficient training of conditional random fields},
  author={Wallach, Hanna},
  year={2002},
  school={University of Edinburgh}
}

@inproceedings{sha2003shallow,
  title={Shallow parsing with conditional random fields},
  author={Sha, Fei and Pereira, Fernando},
  booktitle={NAACL},
  year={2003}
}

@inproceedings{vishwanathan_accelerated_2006,
	title = {Accelerated {Training} of {Conditional} {Random} {Fields} with {Stochastic} {Gradient} {Methods}},
	url = {http://doi.acm.org/10.1145/1143844.1143966},
	booktitle = {ICML},
	author = {Vishwanathan, S. V. N. and Schraudolph, Nicol N. and Schmidt, Mark W. and Murphy, Kevin P.},
	year = {2006},
}

@inproceedings{finkel_efficient_2008,
	title = {Efficient, {Feature}-based, {Conditional} {Random} {Field} {Parsing}},
	url = {http://aclasb.dfki.de/nlp/bib/P08-1109},
	publisher = {Association for Computational Linguistics},
	author = {Finkel, Jenny Rose and Kleeman, Alex and Manning, Christopher D.},
	booktitle = {ACL},
	year = {2008},
}

@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={NIPS},
  year={2013}
}

@book{blackard_comparative_1999,
	title = {Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables},
	author = {Blackard, Jock A. and Dean, Denis J.},
}

@inproceedings{lebanon2002boosting,
  title={Boosting and maximum likelihood for exponential models},
  author={Lebanon, Guy and Lafferty, John D},
  booktitle={NIPS},
  year={2002}
}

@inproceedings{lacoste2013block,
  title={Block-Coordinate {Frank-Wolfe} Optimization for Structural {SVM}s},
  author={Lacoste-Julien, Simon and Jaggi, Martin and Schmidt, Mark and Pletscher, Patrick},
  booktitle={ICML},
  year={2013}
}

@article{shalev2016accelerated,
  title={Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={Mathematical Programming},
  year={2016},
  publisher={Springer}
}

@inproceedings{kirshnan15barrierFW,
  title={Barrier {F}rank-{W}olfe for marginal inference},
  author={Rahul G. Krishnan and Simon Lacoste-Julien and David Sontag},
  booktitle={NIPS},
  year={2015}
}

@inproceedings{dunner2017efficient,
  title={Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems},
  author={D{\"u}nner, Celestine and Parnell, Thomas and Jaggi, Martin},
  booktitle={NIPS},
  year={2017}
}

@book{koller2009PGM,
  title={Probabilistic Graphical Models},
  author={Daphne Koller and Nir Friedman},
  publisher={The MIT Press},
  year={2009}
}

@inproceedings{lin2015catalyst,
  title = {A Universal Catalyst for First-Order Optimization},
  booktitle = {NIPS},
  author = {Hongzhou Lin and Julien Mairal and Zaid Harchaoui},
  year = {2015},
  }

@article{walt2011numpy,
  title={The NumPy array: a structure for efficient numerical computation},
  author={Walt, St{\'e}fan van der and Colbert, S Chris and Varoquaux, Gael},
  journal={Computing in Science \& Engineering},
  year={2011},
  publisher={IEEE}
}



@InProceedings{perekrestenko17a,
  title = 	 {Faster Coordinate Descent via Adaptive Importance Sampling},
  author = 	 {Dmytro Perekrestenko and Volkan Cevher and Martin Jaggi},
  booktitle =   {AISTATS},
  year = 	 {2017},
  pdf = 	 {http://proceedings.mlr.press/v54/perekrestenko17a/perekrestenko17a.pdf},
}

@book{nesterov_introductory_2004,
  series = {Applied Optimization},
  title = {Introductory Lectures on Convex Optimization},
  publisher = {{Springer US}},
  author = {Nesterov, Yurii},
  year = {2004},
}
